[{"id":"1","name":"Environment Setup","content":"<h2 id=\"environmentsetup\">Environment Setup</h2>\n<p>Devs, SREs, and Operations all need actionable observability into their cloud infrastructure and cloud native platforms.&nbsp;</p>\n<h3 id=\"inthissessionyouwilllearnhowto\">In this session, you will learn how to:</h3>\n<ul>\n<li>Analyze the availability, health, and resource utilization of your Kubernetes infrastructure</li>\n<li>Integrate Dynatrace with your cloud platforms to capture key metrics and logs in context</li>\n<li>Track the health, utilization, and performance of your cloud infrastructure and services</li>\n<li>Leverage Dynatrace to speed up your cloud migration and modernization project</li>\n<li>Build AI-Powered Alerts and leverage Davis to get to the root cause quick when issues arise</li>\n<li>Deploy dashboards to track health and performance of your cloud infrastructure</li>\n</ul>","activityList":[{"id":"1.1","name":"Login to Dynatrace University and your Dynatrace Tenant","content":"<h2 id=\"logintodynatraceuniversityandyourdynatracetenant\">Login to Dynatrace University and your Dynatrace Tenant</h2>\n<p>In this lab you'll learn how to create a container image and how to run a container based on this image. During this activity you will pull an image from a global container registry to get hands-on experience with container registries in general.</p>\n<h3 id=\"indynatraceuniversity\">In Dynatrace University:</h3>\n<ul>\n<li>Navigate to Dashboard</li>\n<li>Upcoming Events – Getting Started with Dynatrace Cloud Infrastructure Observability</li>\n<li>Environments Tab: Contains your Dynatrace environment, VM, passwords, and terminal</li>\n<li>Activities: Exercise instructions and commands to copy/paste</li>\n</ul>\n<h3 id=\"logintodynatraceui\">Log into Dynatrace UI</h3>\n<ul>\n<li>Use the username and password provided in DTU</li>\n</ul>","activityList":[]},{"id":"1.2","name":"Enable K8s Events","content":"<h2 id=\"enablek8sevents\">Enable K8s Events</h2>\n<p>Let's enable k8s events for your cluster!</p>\n<h3 id=\"inthedynatraceui\">In the Dynatrace UI:</h3>\n<ul>\n<li>Navigate to Kubernetes in the left hand menu</li>\n<li>Select your cluster from the list</li>\n<li>Click the button with the ellipses to the far and then settings from the dropdown menu</li>\n<li>Under the Monitoring Settings tab enable Monitor Events.</li>\n<li>Note Events can be filtered prior to ingestion using the Filter Events&nbsp;toggle</li>\n</ul>\n<p><img src=\"assets/k8sturnon.png\" alt=\"k8sturnon\" /></p>","activityList":[]},{"id":"1.3","name":"Turn on Log Monitoring","content":"<h2 id=\"turnonlogmonitoring\">Turn on Log Monitoring</h2>\n<p>By default, Dynatrace auto-discovers logs, but we must tell it to ingest those discovered logs.</p>\n<h3 id=\"inthedynatraceui\">In the Dynatrace UI:</h3>\n<ul>\n<li>Navigate to Settings&gt; Log Monitoring &gt; Log Sources and Storage.</li>\n<li>Change the drop down scope to “include all logs” and save changes.</li>\n</ul>\n<p><img src=\"assets/logenable.png\" alt=\"logenable\" /></p>","activityList":[]}]},{"id":"2","name":"AWS Cloudwatch Infrastructure Monitoring","content":"<h2 id=\"awscloudwatchinfrastructuremonitoring\">AWS Cloudwatch Infrastructure Monitoring</h2>\n<h3 id=\"inthissectionyouwilllearnhowto\">In this section, you will learn how to:</h3>\n<ul>\n<li>Set up AWS integration</li>\n<li>Monitor additional AWS services and AWS service metrics</li>\n<li>Gather additional details than what cloudwatch provides by deploying the oneAgent on the AWS instances(EC2/ECS/Fargate/EKS/Labda)</li>\n<li>Ingesting AWS Cloudwatch metrics consume DDUs</li>\n<li>Visualize the metrics on dashboards (preset and custom)</li>\n<li>Use AWS tags that Dynatrace brings automatically from your AWS entities. They will be used to filter the data to pull from Cloudwatch or filter in Dynatrace dashboards and alerts</li>\n</ul>","activityList":[{"id":"2.1","name":"Adding A Service","content":"<h2 id=\"addingaservice\">Adding A Service</h2>\n<p>One of our teams have just migrated their&nbsp;application to AWS. This application includes invocations to AWS SQS, currently not being monitored in Dynatrace. Add the AWS SQS services to be monitored in Dynatrace.&nbsp;</p>\n<ol>\n<li>Access to Dynatrace UI</li>\n<li>Click on Setting, on the left Menu&nbsp;</li>\n<li>Expand the \"Cloud and virtualization\" section</li>\n<li>Select AWS</li>\n<li>Edit (pencil icon) the current AWS connection</li>\n<li>Click on Manage Services</li>\n<li>Add a new Service</li>\n<li>Search the SQS service and click on Add Service</li>\n</ol>\n<ul>\n<li>Note: Don’t save it, as you don’t have the permissions to add it</li>\n</ul>","activityList":[]},{"id":"2.2","name":"Monitor additional service metrics","content":"<h2 id=\"monitoradditionalservicemetrics\">Monitor additional service metrics</h2>\n<p>The application team that uses AWS Kinesis Data streams wants to monitor additional metrics due to the high increase of utilization. They would like to know if the \"IncomingRecords\" are still under the initially scope range or higher.​</p>\n<p>Add the metric \"IncomingRecords\" to the AWS Kinesis Data Streams</p>\n<ol>\n<li>Access to Dynatrace UI​</li>\n<li>Click on Setting, on the left Menu ​</li>\n<li>Expand the \"Cloud and virtualization\" section​</li>\n<li>Select AWS​</li>\n<li>Edit (pencil icon) the current AWS connection​</li>\n<li>Click on Manage Services​</li>\n<li>Select the Service \"AWS Kinesis Data Streams\"​</li>\n<li>Click on Add Metric​</li>\n<li>Select the \"IncommingRecords\" metric ​</li>\n<li>Select the statistics \"Average + Minimum + Maximum\"​</li>\n<li>Select the dimension \"StreamName\"​</li>\n<li>Add metric​</li>\n</ol>\n<ul>\n<li>Note: Don’t save it, as you don’t have the permissions to add it</li>\n</ul>","activityList":[]},{"id":"2.3","name":"Create your custom dashboard","content":"<h2 id=\"createyourcustomdashboard\">Create your custom dashboard</h2>\n<p>Create a dashboard to monitor some infrastructure metrics from your AWS environment​</p>\n<p><img src=\"assets/02_03_customdashboard.png\" alt=\"02_03_customdashboard\" /></p>","activityList":[]},{"id":"2.4","name":"Top CPU utilization","content":"<h2 id=\"topcpuutilization\">Top CPU utilization</h2>\n<p>Chart top CPU utilization from your EC2 instances​\n<img src=\"assets/02_04_topcpu.png\" alt=\"02_04_topcpu\" /></p>\n<ol>\n<li>Select on the left Menu \"Data explorer\"​</li>\n<li>On the top right corner, select the chart as \"Top list\"​</li>\n<li>On the metric selection type \"EC2 CPU usage %\"​</li>\n<li>Leave aggregation as Auto(avg)​</li>\n<li>Split by \"EC2 instance\"​</li>\n</ol>\n<p><img src=\"assets/02_04_metricselector.png\" alt=\"02_04_metricselector\" /></p>\n<ol start=\"6\">\n<li>Click on \"Run query\" button​</li>\n</ol>\n<p><img src=\"assets/02_04_run.png\" alt=\"02_04_run\" /></p>\n<ol start=\"7\">\n<li>On the right side set the thresholds : green ≥ 0 , yellow ≥ 70, red ≥ 90 ​</li>\n</ol>\n<p><img src=\"assets/02_04_thresholds.png\" alt=\"02_04_thresholds\" /></p>\n<ol start=\"8\">\n<li>Click on \"Pin to Dashboard\" button and select \"Create new dashboard\"​</li>\n</ol>\n<p><img src=\"assets/02_04_pintodashboard.png\" alt=\"02_04_pintodashboard\" /></p>\n<ol start=\"9\">\n<li>Open your new dashboard and rename it as \"AWS overview\"​</li>\n</ol>","activityList":[]},{"id":"2.5","name":"Unused provisioned volumes","content":"<h2 id=\"unusedprovisionedvolumes\">Unused provisioned volumes</h2>\n<p>Identify if you have EBS volumes allocated but with very low utilization\nBy monitor this metric you can verify that provisioned resources are not going unused. Sudden spikes in idle time could indicate issues in your application, preventing it from sending requests the provisioned volumes.​</p>\n<p><img src=\"assets/02_05_ebsidle.png\" alt=\"02_05_ebsidle\" /></p>\n<ol>\n<li>Select on the left Menu \"Data explorer\"​</li>\n<li>On the top right corner, select the chart as \"Graph\"​</li>\n</ol>\n<p><img src=\"assets/02_05_chartselector.png\" alt=\"02_05_chartselector\" /></p>\n<ol start=\"3\">\n<li>On the metric selection type \"EBS volume idle time %\"​</li>\n<li>Leave aggregation as Auto(avg)​</li>\n<li>Split by \"EBS volume\"​</li>\n<li>Click on \"Run query\" button​</li>\n<li>Click on \"Pin to Dashboard\" button and add it to your dashboard \"AWS overview\"</li>\n</ol>","activityList":[]},{"id":"2.6","name":"(Optional) EC2 Memory","content":"<h2 id=\"optionalec2memory\">(Optional) EC2 Memory</h2>\n<p>Chart the memory consumed by your EC2 instances​</p>\n<p><img src=\"assets/02_06_ec2memory.png\" alt=\"02_06_ec2memory\" /></p>\n<ol>\n<li>Select on the left Menu \"Data explorer\"​</li>\n<li>On the top right corner, select the chart as \"Graph\"​</li>\n<li>On the metric selection type \"builtin:host.mem.usage\"​</li>\n<li>Leave aggregation as Auto(avg)​</li>\n<li>Split by \"Host\"​</li>\n<li>Filter by \"Host\" &gt; \"Cloud Type\" &gt; \"EC2\"​</li>\n<li>Click on \"Run query\" button​</li>\n<li>On the right menu​</li>\n<li>In \"Axes\" section, edit the \"Left\" \"Min, Max\" to 0, 100​</li>\n<li>In Threshold section,  yellow ≥ 70, red ≥ 90  (leave green without any value)​</li>\n<li>Click on \"Pin to Dashboard\" button and add it to your dashboard \"AWS overview\"​</li>\n</ol>","activityList":[]},{"id":"2.7","name":"(Optional) Application Load Balancer","content":"<h2 id=\"optionalapplicationloadbalancer\">(Optional) Application Load Balancer</h2>\n<p>Display 4xx and 5xx errors seen by the Application Load Balancer (ALB)​</p>\n<p><img src=\"assets/02_07_alb.png\" alt=\"02_07_alb\" /></p>\n<ol>\n<li>Select on the left Menu \"Data explorer\"​</li>\n<li>On the top right corner, select the chart as \"Graph\"​</li>\n<li>On the metric selection type \"ALB number of 5XX errors\"​</li>\n<li>Leave aggregation as Auto(avg)​</li>\n<li>Split by \"Application load balancer\"​</li>\n<li>Add a second metric​</li>\n<li>On the metric selection type \"ALB number of 4XX errors\"​</li>\n<li>Leave aggregation as Auto(avg)​</li>\n<li>Split by \"Application load balancer\"​</li>\n<li>Click on \"Run query\" button​</li>\n<li>Click on \"Pin to Dashboard\" button and add it to your dashboard \"AWS overview\"​</li>\n</ol>","activityList":[]},{"id":"2.8","name":"(Optional) EC2 health","content":"<h2 id=\"optionalec2health\">(Optional) EC2 health</h2>\n<p>Display the health of the EC2 instances where the oneAgent is installed</p>\n<p><img src=\"assets/02_08_ec2health.png\" alt=\"02_08_ec2health\" /></p>\n<ol>\n<li>Select on the left Menu \"Hosts\"​</li>\n<li>On the top  box \"Filter by\" &gt; \"Type\" &gt; \" AWS Elastic Compute Cloud\"​</li>\n<li>Click on \"Pin to Dashboard\" button and add it to your dashboard \"AWS overview\"</li>\n</ol>","activityList":[]}]},{"id":"3","name":"Alerting","content":"<h2 id=\"alerting\">Alerting</h2>\n<h3 id=\"learningconcepts\">Learning Concepts</h3>\n<ul>\n<li>Dynatrace provides out of the box anomaly detection for many app, service, and infrastructure problems.</li>\n<li>For each anomaly type, you can either select automatic detection to rely on Davis to alert you about problems, or you can provide a fixed threshold.</li>\n<li>You can also create your own alerts on metrics in Dynatrace</li>\n<li>Static Thresholds</li>\n<li>Auto-Adaptive Thresholds</li>\n<li>Seasonal Baselines</li>\n<li>Alerting Profiles are used to filter/group alerts</li>\n<li>Problem Notifications are used to send alerts or notifications when thresholds are breached or anomalies are detected.</li>\n<li>Dynatrace has integrations with Incident Management , ChatOps, and Service Management solutions</li>\n<li>Dynatrace can also send problem notifications via webhook or email</li>\n</ul>","activityList":[{"id":"3.1","name":"Create Static Threshold Alert","content":"<h2 id=\"createstaticthresholdalert\">Create Static Threshold Alert</h2>\n<p>While Dynatrace will automatically detect when disk space is low, a few of our app teams are noisy loggers and we want to warn them of disk space utilization earlier.\nWe don’t want to change the OOTB Anomaly Detection as that will let us know when disk is critical. We just want an early warning alert.</p>\n<p><img src=\"assets/staticthreshold.png\" alt=\"staticthreshold\" /></p>\n<h3 id=\"exercisesteps\">Exercise Steps</h3>\n<ol>\n<li>Navigate to Settings &gt; Anomaly Detection &gt; Metric Events</li>\n<li>Add a Metric Event</li>\n</ol>\n<ul>\n<li>Name: Disk Warning</li>\n<li>Type: Metric Key</li>\n<li>Metric Key: Disk Used %</li>\n<li>Aggregation: Average*</li>\n<li>Model Type: Static Threshold</li>\n<li>Threshold: 80%</li>\n<li>Alert Condition: Alert if metric is above</li>\n<li>Preview the alert with last 1, 3, and 7 days worth of data</li>\n<li>Title: Disk Warning</li>\n<li>Event Type: Custom Alert</li>\n<li>Do not allow to merge</li>\n</ul>","activityList":[]},{"id":"3.2","name":"Create an Auto-Adaptive Alert","content":"<h2 id=\"createanautoadaptivealert\">Create an Auto-Adaptive Alert</h2>\n<ul>\n<li>We sometimes get 4xx errors on the ALB and have accepted that we can’t fix 100% of errors.</li>\n<li>However, we want to Dynatrace to tell us if errors spike up outside of the norm without having to create thresholds ourselves.</li>\n<li>The number of errors may fluctuate, and it would be great if Dynatrace could auto-adapt and let us know when big spikes occur</li>\n</ul>\n<p><img src=\"assets/autoadaptive.png\" alt=\"autoadaptive\" /></p>\n<h3 id=\"exercisesteps\">Exercise Steps</h3>\n<ol>\n<li>Navigate to Settings &gt; Anomaly Detection &gt; Metric Events</li>\n<li>Add a Metric Event</li>\n</ol>\n<ul>\n<li>Name: ALB Errors</li>\n<li>Type: Metric Selector</li>\n<li>Metric Selector: builtin:cloud.aws.alb.errors.alb.http4xx&nbsp;</li>\n<li>Model Type: Auto-Adaptive Threshold</li>\n<li>Don’t alert on missing data</li>\n<li>Alert Condition: Alert if metric is above</li>\n<li>Preview the alert with last 1, 3, and 7 days' worth of data</li>\n<li>Title: ALB Errors</li>\n<li>Event Type: Error</li>\n<li>Allow to merge</li>\n</ul>","activityList":[]},{"id":"3.3","name":"Set Alerts to Alerting Profile","content":"<h2 id=\"setalertstoalertingprofile\">Set Alerts to Alerting Profile</h2>\n<ul>\n<li>We want send a notification just to the app team with the noisy logging when the Disk Warning Triggers.</li>\n<li>We can group alerts based on severity, impact, and tags with alerting profiles.</li>\n</ul>\n<p><img src=\"assets/diskalert1.png\" alt=\"diskalert1\" /></p>\n<h3 id=\"exercisesteps\">Exercise Steps</h3>\n<ol>\n<li>Navigate to Settings &gt; Alerting &gt; Problem Alerting Profiles</li>\n<li>Add a Metric Event for just the Disk Warning Alert</li>\n</ol>\n<ul>\n<li>Name: Disk Warning</li>\n<li>Problem Severity: Custom</li>\n<li>Problem Delay in Minutes: 10 minutes</li>\n<li>Filter problems by tag: Include All Entities</li>\n<li>Event Filter: Custom</li>\n<li>Title Filter: Equals Disk Warning</li>\n<li>Enabled</li>\n<li>Save Changes</li>\n</ul>\n<p><img src=\"assets/diskalert2.png\" alt=\"diskalert2\" /></p>","activityList":[]},{"id":"3.4","name":"Email Alert","content":"<h2 id=\"emailalert\">Email Alert</h2>\n<ul>\n<li>Now that we’ve created an Alerting Profile (filtered/grouped the alerts), let’s tell Dynatrace what to do when that triggers.</li>\n</ul>\n<p><img src=\"assets/emailalert1.png\" alt=\"emailalert1\" /></p>\n<h3 id=\"exercisesteps\">Exercise Steps</h3>\n<ol>\n<li>Navigated to Settings &gt; Integration &gt; Problem Notifications</li>\n<li>Add notification</li>\n</ol>\n<ul>\n<li>Notification type: Email</li>\n<li>Display Name: Disk Warning</li>\n<li>To: Your Email Address</li>\n<li>Alerting Profile: Disk Warning</li>\n<li>Save Changes</li>\n</ul>\n<ol>\n<li>Send test notification</li>\n</ol>\n<p><img src=\"assets/emailalert2.png\" alt=\"emailalert2\" /></p>","activityList":[]}]},{"id":"4","name":"AWS Cloudwatch Logs","content":"<h2 id=\"awscloudwatchlogs\">AWS Cloudwatch Logs</h2>\n<h3 id=\"learningconcepts\">Learning Concepts</h3>\n<ul>\n<li>Dynatrace ingests AWS Cloudwatch logs to help you get to the root cause of issues with your AWS services and infrastructure.</li>\n<li>Dynatrace enriches logs and links them to your AWS entities for ease of analysis and quicker troubleshooting.</li>\n<li>Dynatrace allows you to define log events and custom log metrics to receive alerts.</li>\n<li>Dynatrace allows you to use parsing rules to get key attributes out of logs, create metrics on those attributes and to alert on those log metrics. </li>\n</ul>","activityList":[{"id":"4.1","name":"Troubleshooting","content":"<h2 id=\"troubleshooting\">Troubleshooting</h2>\n<p>We want to be able to see the newest error logs coming from our AWS Services</p>\n<p><img src=\"assets/logtroubleshooting.png\" alt=\"logtroubleshooting\" /></p>\n<h3 id=\"exercisesteps\">Exercise Steps</h3>\n<ul>\n<li>Navigate to the log viewer in Dynatrace</li>\n<li>Filter for only the Error Logs</li>\n<li>Format the table: Add in AWS Region</li>\n<li>Add it to dashboard</li>\n</ul>","activityList":[]},{"id":"4.2","name":"Log Entity Linking","content":"<h2 id=\"logentitylinking\">Log Entity Linking</h2>\n<ul>\n<li>This exercise is not working as we need to add the entity information into the log script. Will be adding before perform.</li>\n</ul>","activityList":[]},{"id":"4.3","name":"Log Event","content":"<h2 id=\"logevent\">Log Event</h2>\n<ul>\n<li>I shouldn’t see any connection issues coming from my RDS instance, but it’s happened in the past</li>\n<li>When that happens, I want Dynatrace to create a log event and alert on it.</li>\n</ul>\n<p><img src=\"assets/logevent1.png\" alt=\"logevent1\" /></p>\n<h3 id=\"findtherdslog\">Find the RDS Log</h3>\n<ul>\n<li>Find the RDS connect error log records</li>\n<li>Search content:</li>\n</ul>\n<pre><code class=\"hljs bash language-bash\">unable to connect\n</code></pre>\n<ul>\n<li>Copy the entire log content</li>\n</ul>\n<p><img src=\"assets/logevent2.png\" alt=\"logevent2\" /></p>\n<h3 id=\"createlogevent\">Create Log Event</h3>\n<ul>\n<li>Navigate to Settings&gt; Log Monitoring&gt; Events Extraction</li>\n<li>Add log event</li>\n<li>Summary: RDS Connection Error</li>\n<li>Log Query:</li>\n</ul>\n<pre><code class=\"hljs bash language-bash\">content=<span class=\"hljs-string\">&quot;error: 2 The following error occurred: Can&#x27;t connect to MySQL server on &#x27;db-qig94285-ac32d6-2a.rds.amazonaws.com&#x27; (10060) QMYSQL: Unable to connect”\n</span></code></pre>\n<ul>\n<li>Title: RDS Connection Error</li>\n<li>Event Type: Error</li>\n<li>Allow to Merge</li>\n<li>Save Changes</li>\n</ul>","activityList":[]},{"id":"4.4","name":"Log Metric","content":"<h2 id=\"logmetric\">Log Metric</h2>\n<ul>\n<li>We’ve seen some spikes in response time and want to see if the CLB is part of the problem</li>\n<li>I want to create a metric off request processing time that’s found in the CLB logs and track it over time</li>\n</ul>\n<h3 id=\"firstletslookattheclblogs\">First let’s look at the CLB logs</h3>\n<ul>\n<li>In the log viewer, search for</li>\n</ul>\n<pre><code class=\"hljs bash language-bash\">content=<span class=\"hljs-string\">&quot;clb”\n</span></code></pre>\n<ul>\n<li>Notice how there’s a lot of numbers in the log?</li>\n<li>We can parse these to use them in queries and metrics!</li>\n<li>Click Create processing rule</li>\n</ul>\n<p><img src=\"assets/logmetric1.png\" alt=\"logmetric1\" /></p>\n<h3 id=\"clblogparserwithloglevel\">CLB Log Parser with log level</h3>\n<ul>\n<li>We need to create 2 parsers because sometimes the logs have info: or error: in front of the content and sometimes it doesn’t.</li>\n<li>The parsers are prioritized top down, so the way we order the parsing rules changes the way Dynatrace applies them</li>\n<li>Matcher:</li>\n</ul>\n<pre><code class=\"hljs bash language-bash\">content=<span class=\"hljs-string\">&quot;: clb”\n</span></code></pre>\n<ul>\n<li>Parser:</li>\n</ul>\n<pre><code class=\"hljs bash language-bash\">PARSE(content, <span class=\"hljs-string\">&quot;LD:log.level &#x27;:&#x27; SPACE STRING:clb.name SPACE IPADDR:client.ip &#x27;:&#x27; INT:client.port SPACE IPADDR:backend.ip &#x27;:&#x27; INT:&#x27;backend.port&#x27; SPACE double:&#x27;request.processing.time&#x27; SPACE double:&#x27;backend.processing.time&#x27;\nSPACE double:&#x27;response.processing.time&#x27; SPACE INT:elb.status_code SPACE INT:backend.status.code SPACE INT:recieved.bytes SPACE INT:sent.bytes SPACE STRING:request SPACE&quot;</span>)\n</code></pre>\n<p><img src=\"assets/logmetric2.png\" alt=\"logmetric2\" /></p>\n<h3 id=\"clblogparserwithloglevel-1\">CLB Log Parser with log level</h3>\n<ul>\n<li>Matcher:</li>\n</ul>\n<pre><code class=\"hljs bash language-bash\">content=<span class=\"hljs-string\">&quot;clb”\n</span></code></pre>\n<ul>\n<li>Parser:</li>\n</ul>\n<pre><code class=\"hljs bash language-bash\">PARSE(content, <span class=\"hljs-string\">&quot;STRING:clb.name SPACE IPADDR:client.ip &#x27;:&#x27; INT:client.port SPACE IPADDR:backend.ip &#x27;:&#x27; INT:&#x27;backend.port&#x27; SPACE double:&#x27;request.processing.time&#x27; SPACE double:&#x27;backend.processing.time&#x27;\nSPACE double:&#x27;response.processing.time&#x27; SPACE INT:elb.status_code SPACE INT:backend.status.code SPACE INT:recieved.bytes SPACE INT:sent.bytes SPACE STRING:request SPACE&quot;</span>)\n</code></pre>\n<ul>\n<li>Ensure the without log level rule is under the with rule</li>\n</ul>\n<p><img src=\"assets/logmetric3.png\" alt=\"logmetric3\" /></p>\n<h3 id=\"createthemetric\">Create the Metric</h3>\n<ul>\n<li>Now that the log is parsed out, let’s take a look at how new CLB logs look in the log viewer</li>\n<li>All of these attributes can be used for log metrics!</li>\n<li>Click Create Metric  </li>\n<li>Metric key: log.clb.requestprocessingtime</li>\n<li>Matcher:  content=\"clb”</li>\n<li>Metric Measurement: Attribute Value</li>\n<li>Attribute: request.processing.time</li>\n<li>Click Save changes</li>\n</ul>\n<p><img src=\"assets/logmetric4.png\" alt=\"logmetric4\" />\n<img src=\"assets/logmetric5.png\" alt=\"logmetric5\" /></p>\n<h3 id=\"addthemetrictothedashboard\">Add the metric to the dashboard</h3>\n<ul>\n<li>Once we get some new data in, we can chart out the new log metric and add it to our Cloud Infrastructure Overview dashboard</li>\n<li>Navigate to Data Explorer</li>\n<li>Type in log.clb to find your metric</li>\n<li>Run Query</li>\n<li>Pin to dashboard\n<img src=\"assets/logmetric6.png\" alt=\"logmetric6\" /></li>\n</ul>","activityList":[]},{"id":"4.5","name":"Log Metric Alert","content":"<h2 id=\"logmetricalert\">Log Metric Alert</h2>\n<ul>\n<li>My AWS networking team wants to alert on the CLB request processing time, but doesn’t know what they should use for the threshold.</li>\n</ul>\n<p><img src=\"assets/logmetricalert.png\" alt=\"logmetricalert\" /></p>\n<h3 id=\"exercisesteps\">Exercise Steps</h3>\n<ul>\n<li>Find the RDS connect error log records</li>\n<li>Navigate to  Settings&gt; Anomaly Detection&gt; Metric Events</li>\n<li>Add metric event</li>\n<li>Summary: CLB Request Processing Time</li>\n<li>Metric Selector: log.clb.requestprocessingtime</li>\n<li>Aggregation: Average</li>\n<li>Model type: Auto-adaptive threshold</li>\n<li>Do not alert on missing data (best practice for log metrics)</li>\n<li>Alerting Condition Alert if metric is above</li>\n<li>Title: CLB Request Processing Time</li>\n<li>Event Type: Slowdown</li>\n<li>Allow to merge</li>\n<li>Save Changes</li>\n</ul>","activityList":[]}]},{"id":"5","name":"Kubernetes Environment Set up","content":"<h2 id=\"kubernetesenvironmentsetup\">Kubernetes Environment Set up</h2>","activityList":[]},{"id":"6","name":"Kubernetes Platform Health ","content":"<h2 id=\"kubernetesplatformhealth\">Kubernetes Platform Health</h2>\n<h3 id=\"learningconcepts\">Learning Concepts</h3>\n<h2 id=\"kubernetesoperatordeploymentmodelbydefaultdynatracedeploystheclassicfullstackmodewherewerolloutaoneagentpodpernodetomonitoritandthenodeitself\">- Kubernetes Operator Deployment Model, by default Dynatrace deploys the \"ClassicFullStack\" mode. Where we roll out a OneAgent pod per node to monitor it and the node itself. </h2>","activityList":[{"id":"6.1","name":"Kubernetes Navigation ","content":"<h2 id=\"kubernetesnavigation\">Kubernetes Navigation</h2>\n<p><img src=\"assets/06_01_k8s_navigation.png\" alt=\"Navigation\" /></p>\n<h3 id=\"exercisesteps\">Exercise Steps</h3>\n<ol>\n<li>Navigate to Infrastructure &gt; Kubernetes &gt; dynakube </li>\n<li>Click into the cluster: dynakube </li>\n</ol>\n<ul>\n<li>Navigate: Check the k8s Cluster Page​</li>\n<li>Navigate: Check the k8s Node page​</li>\n<li>Navigate: Check a Namespace​</li>\n<li>Navigate: Check a Workload​</li>\n<li>Navigate: Check a Service​</li>\n<li>Navigate: Check a Pod​</li>\n<li>Navigate: Check a Container</li>\n</ul>\n<ol>\n<li>What is the total number of workloads for dynakube? </li>\n</ol>","activityList":[]},{"id":"6.2","name":"Kubernetes Naviation ","content":"<h2 id=\"kubernetesnaviation\">Kubernetes Naviation</h2>\n<h3 id=\"exercisesteps\">Exercise Steps</h3>\n<ol>\n<li>Navigate to Kubernetes &gt; dynakube &gt; Namespaces &gt; \"easytrade\" </li>\n</ol>\n<ul>\n<li>Pin a metric from Namespace \"easytrade\" to your \"Cloud Infrastructure Overview\" dashboard</li>\n<li>What is the max resource analysis for both Memory (GiB) and CPU (cores)? </li>\n<li>What is the max workload analysis for Pods and Workloads in the \"easytrade\" namespace? </li>\n</ul>","activityList":[]}]},{"id":"7","name":"K8s Alerts\r","content":"<h2 id=\"k8salerts\">K8s Alerts</h2>\n<p>Dynatrace provides a number of out-of-the-box alerts to monitor your Kubernetest environment based on best practices. These will continue to grow over time. However, you are not limited to only these built-in alerts.</p>\n<p>In this section we will take a look at one of these out-of-the-box Kubernetes alerts and also how you can create your own custom alert based on a Kubernetes metric.</p>","activityList":[{"id":"7.1","name":"Built-in Alerting\r","content":"<h2 id=\"builtinalerting\">Built-in Alerting</h2>\n<h3 id=\"enableandtestabuiltinalert\">Enable and test a built-in alert!</h3>\n<ol>\n<li>Navigate to Settings &gt; Anomaly detection&gt; Kubernetes/Workload</li>\n<li>Enable <strong>Detect pending pods</strong>*</li>\n<li>Expand the Configuration section and set pending state for at least <strong>5</strong> minutes within last <strong>10</strong> minutes.</li>\n</ol>\n<blockquote>\n  <p>NOTE: Original values are 10 minutes in last 15 minutes</p>\n</blockquote>\n<p><img src=\"assets/k8s_pending_pods.png\" alt=\"pending_pod\" /></p>\n<ol start=\"4\">\n<li>In your shell run the following command to scale up the <strong>loginservice</strong> to far exceed capacity:</li>\n</ol>\n<pre><code class=\"hljs bash language-bash\">kubectl scale --replicas=100 deployment/loginservice -n easytrade\n</code></pre>\n<ol start=\"5\">\n<li>Run the following command and note pods that are stuck in a <strong>Pending</strong> state:</li>\n</ol>\n<pre><code class=\"hljs bash language-bash\">kubectl get pods -l app=loginservice -n easytrade\n</code></pre>\n<ol start=\"6\">\n<li>A \"Pending pods\" problem will open in about 5 minutes</li>\n</ol>\n<p><img src=\"assets/k8s_pending_pod_problem.png\" alt=\"problem\" /></p>\n<ol start=\"7\">\n<li>Run the following command to scale the <strong>loginservice</strong> down to 3 replicas:</li>\n</ol>\n<pre><code class=\"hljs bash language-bash\">kubectl scale --replicas=3 deployment/loginservice -n easytrade\n</code></pre>","activityList":[]},{"id":"7.2","name":"Custom Alerting\r","content":"<h2 id=\"customalerting\">Custom Alerting</h2>\n<h3 id=\"configureacustomalertbasedonrunningpodsmetric\">Configure a custom alert based on running pods metric</h3>\n<ol>\n<li>Navigate to Settings &gt; Anomaly detection &gt; Metric events</li>\n</ol>\n<p><img src=\"assets/k8s_metric_events.png\" alt=\"metric_events\" /></p>\n<ol start=\"2\">\n<li>Click the <strong>Add metric event</strong> button</li>\n<li>Configure the new metric event with the following details</li>\n</ol>\n<ul>\n<li>Summary: <em>Running pods low</em></li>\n<li>Type: <em>Metric key</em></li>\n<li>Metric key: <em>Kubernetes: Pod count (by workload)</em></li>\n<li>Aggregation: <em>Maximum</em></li>\n<li>Configure an entity filter: <em>Name equals loginservice</em></li>\n<li>Threshold: <em>3</em></li>\n<li>Alert condition: <em>Alert if metric is below</em></li>\n<li>Event title: <em>Running pods low for loginservice</em></li>\n<li>Description: <em>The {metricname} value was {alert_condition} normal behavior on workload {dims:k8s.workload.name}.</em></li>\n<li>Event type: <em>Custom</em></li>\n<li>Click the <strong>Save</strong> changes button</li>\n</ul>\n<ol start=\"2\">\n<li>In your shell run the following command to furth scale the <strong>loginservice</strong> down to a single pod:</li>\n</ol>\n<pre><code class=\"hljs bash language-bash\">kubectl scale --replicas=1 deployment/loginservice -n easytrade\n</code></pre>\n<ol start=\"5\">\n<li>A problem will trigger within 5 minutes</li>\n</ol>\n<p><img src=\"assets/k8s_metric_problem.png\" alt=\"metric_problem\" /></p>\n<ol start=\"6\">\n<li>Adjust the threshold on the previously created metric event to <strong>1</strong> to clear the problem</li>\n</ol>","activityList":[]},{"id":"7.3","name":"OOM Alert\r","content":"<h2 id=\"oomalert\">OOM Alert</h2>\n<h3 id=\"configureacustomalertforoomkillsoncontainers\">Configure a custom alert for OOM Kills on containers</h3>\n<ol>\n<li>Navigate to Settings &gt; Anomaly detection &gt; Metric events</li>\n<li>Click the <strong>Add metric event</strong> button</li>\n<li>Configure the new metric event with the following details</li>\n</ol>\n<ul>\n<li>Summary: <em>Container OOMKills High</em></li>\n<li>Type: <em>Metric key</em></li>\n<li>Metric key: <em>Kubernetes: Container - out of memory (OOM) kill count</em></li>\n<li>Static Threshold: <em>1</em></li>\n<li>Event title: <em>Container OOMKills high for {entityname}</em></li>\n</ul>\n<ol>\n<li>Click the <strong>Save</strong> changes button</li>\n</ol>","activityList":[]}]},{"id":"8","name":"Logs and Events","content":"<h2 id=\"logsandevents\">Logs and Events</h2>\n<h3 id=\"k8sevents\">K8s Events:</h3>\n<ul>\n<li>K8s Events can be used to determine&nbsp;the health and status&nbsp;of critical&nbsp;components in your&nbsp;environment</li>\n<li>Events will be visible on all k8s entities in Dynatrace&nbsp;</li>\n<li>Ensure k8s events are captured by enabling them in the settings section of your cluster</li>\n</ul>\n<h3 id=\"k8slogs\">K8s Logs:</h3>\n<ul>\n<li>K8s System Logs are ingested from Nodes while Application logs are ingested from pods</li>\n<li>Logs will be visible on all k8s entities in Dynatrace&nbsp;</li>\n<li>Log storage is enabled in global settings</li>\n<li>Logs ingestion is enabled at the host level</li>\n</ul>\n<h3 id=\"alertsmetrics\">Alerts &amp; Metrics:</h3>\n<ul>\n<li>You can create alerts and metrics from k8s events and logs by using the log viewer</li>\n</ul>","activityList":[{"id":"8.1","name":"Finding Events","content":"<h2 id=\"findingevents\">Finding Events</h2>\n<p><img src=\"assets/k8sevents1.png\" alt=\"events\" /></p>\n<h3 id=\"exercisesteps\">Exercise Steps</h3>\n<ol>\n<li>Let's see where events appear: ​</li>\n</ol>\n<ul>\n<li>Check the k8s Cluster Page​</li>\n<li>Check the k8s Node page​</li>\n<li>Check a Namespace​</li>\n<li>Check a Workload​</li>\n<li>Check a Service​</li>\n<li>Check a Pod​</li>\n<li>Check a Container</li>\n</ul>","activityList":[]},{"id":"8.2","name":"Charting Events","content":"<h2 id=\"chartingevents\">Charting Events</h2>\n<h3 id=\"exercisesteps\">Exercise Steps</h3>\n<ol>\n<li>Navigate to the Logs &amp; Events Viewer​</li>\n<li>Filter by event.type: k8s​</li>\n</ol>\n<pre><code class=\"hljs bash language-bash\">event.type: k8s​\n</code></pre>\n<ol start=\"3\">\n<li>Click into an event entry to see what attributes are captured​</li>\n<li>Add a filter for our node​</li>\n</ol>\n<pre><code class=\"hljs bash language-bash\">dt.kubernetes.node.name: NODE_NAME\n</code></pre>\n<ol start=\"5\">\n<li>Filter the content for Stopping Container events​</li>\n</ol>\n<pre><code class=\"hljs bash language-bash\">content: stopping container\n</code></pre>\n<ol start=\"6\">\n<li>Format the table by adding the fields below:​</li>\n</ol>\n<ul>\n<li>dt.source_entity​</li>\n<li>dt.kubernetes.node.name​</li>\n<li>dt.kubernetes.cluster.name​</li>\n</ul>\n<ol start=\"6\">\n<li>Pin the table to your dashboard</li>\n</ol>\n<p><img src=\"assets/k8sevents2.jpg\" alt=\"charted_events\" /></p>","activityList":[]},{"id":"8.3","name":"Finding Logs","content":"<h2 id=\"findinglogs\">Finding Logs</h2>\n<p><img src=\"assets/k8slogs3.jpg\" alt=\"logs\" /></p>\n<h3 id=\"exercisesteps\">Exercise Steps</h3>\n<ol>\n<li>Let's see where events appear: ​</li>\n</ol>\n<ul>\n<li>Check a Workload​</li>\n<li>Check a Service​</li>\n<li>Check a Pod​</li>\n<li>Check a Container</li>\n<li>Check a Process</li>\n<li>Check a Host</li>\n</ul>","activityList":[]},{"id":"8.4","name":"Charting Logs","content":"<h2 id=\"chartinglogs\">Charting Logs</h2>\n<h3 id=\"exercisesteps\">Exercise Steps</h3>\n<ol>\n<li>Navigate to the Logs &amp; Events Viewer​</li>\n<li>Filter by event.type: log</li>\n</ol>\n<pre><code class=\"hljs bash language-bash\">event.type: <span class=\"hljs-built_in\">log</span>\n</code></pre>\n<ol start=\"3\">\n<li>Click into an log entry to see what attributes are captured​</li>\n<li>Add a filter for our namespace</li>\n</ol>\n<pre><code class=\"hljs bash language-bash\">k8s.namespace.name: NAMESPACE_NAME\n</code></pre>\n<ol start=\"5\">\n<li>Add a filter for our container</li>\n</ol>\n<pre><code class=\"hljs bash language-bash\">k8s.container.name: CONTAINER_NAME\n</code></pre>\n<ol start=\"6\">\n<li>Filter the content for \"update\"​</li>\n</ol>\n<pre><code class=\"hljs bash language-bash\">content: update\n</code></pre>\n<ol start=\"7\">\n<li>Format the table by adding the fields below:​</li>\n</ol>\n<ul>\n<li>dt.source_entity​</li>\n<li>k8s.container.name​</li>\n<li>k8s.namespace.name</li>\n<li>dt.kubernetes.cluster.name​</li>\n</ul>\n<ol start=\"7\">\n<li>Pin the table to your dashboard</li>\n</ol>\n<p><img src=\"assets/k8slogs4.jpg\" alt=\"charted_logs\" /></p>","activityList":[]},{"id":"8.5","name":"Logs Metrics","content":"<h2 id=\"logsmetrics\">Logs Metrics</h2>\n<p><img src=\"assets/k8slogs5.jpg\" alt=\"log_metrics\" /></p>\n<h3 id=\"exercisesteps\">Exercise Steps</h3>\n<ol>\n<li>Click Create Metric</li>\n<li>Make your metric key descriptive</li>\n</ol>\n<pre><code class=\"hljs bash language-bash\">log.k8s.easytrade.frontend.update​\n</code></pre>\n<ol start=\"3\">\n<li>Click save changes​</li>\n</ol>\n<ul>\n<li>This metric can now be used in a Metic Event alert or on a chart</li>\n</ul>","activityList":[]}]},{"id":"9","name":"BizOpsConfigurator Dashboarding ","content":"<h2 id=\"bizopsconfiguratordashboarding\">BizOpsConfigurator Dashboarding</h2>\n<h3 id=\"wespentalotoftimetodaybuildingdashboardswouldntitbecooltoautomatedsomeofthis\">We spent a lot of time today building dashboards, wouldn't it be cool to automated some of this?</h3>\n<ol>\n<li>https://dynatrace.github.io/BizOpsConfigurator</li>\n<li>Enter your tenant URL and API Token</li>\n<li>Deploy Ops, Platform Overview, CPU Utilization (no diamond)</li>\n<li>Deploy Ops, Platform Overview, Disk Utilization (no diamond)</li>\n<li>Deploy Ops, Platform Overview, Memory Utilization (no diamond)</li>\n<li>Deploy Ops, Platform Overview, Network Observability (no diamond)</li>\n<li>Navigate back to the Dynatrace UI and see the new dashboards!</li>\n</ol>","activityList":[{"id":"9.1","name":"Dashboard Creation ","content":"<h2 id=\"dashboardcreation\">Dashboard Creation</h2>\n<p><img src=\"assets/09_01_bizops_config_usecase.png\" alt=\"Usecase\" /></p>\n<h3 id=\"exercisesteps\">Exercise Steps</h3>\n<ol>\n<li>Navigate to https://dynatrace.github.io/BizOpsConfigurator </li>\n<li>Enter your tenant URL and API Token</li>\n</ol>\n<ul>\n<li>Deploy Persona Ops: Platform Overview, CPU Utilization (no diamond)</li>\n<li>Deploy Persona Ops: Platform Overview, Disk Utilization (no diamond)</li>\n<li>Deploy Persona Ops: Platform Overview, Memory Utilization (no diamond)</li>\n<li>Deploy Persona Ops: Platform Overview, Network Observability (no diamond)</li>\n</ul>\n<ol>\n<li>Navigate back to the Dynatrace UI and see the new dashboards!</li>\n</ol>","activityList":[]},{"id":"9.2","name":"Dashboard Export ","content":"<h2 id=\"dashboardexport\">Dashboard Export</h2>\n<h3 id=\"exercisesteps\">Exercise Steps</h3>\n<p><img src=\"assets/09_02_dashboard_export.png\" alt=\"Dashboard\" /></p>\n<h3 id=\"howcanibringmydasboardhomewithme\">How can I bring my dasboard home with me?</h3>\n<ol>\n<li>Navigate to Dashboards &gt; \"Cloud Infrastructure Overview\" dashboard </li>\n<li>Click … Button in upper right corner &gt; Share &gt; Advanced Settings</li>\n<li>Click dashboard JSON &gt; Download</li>\n<li>This is also available in the Configuration API for managing dashboards at scale</li>\n</ol>","activityList":[]}]}]